{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eQUTHO-WPc03",
    "outputId": "10eff814-5913-44e8-98dc-43cf08d49403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YBIGTA_Transfer_Learning.ipynb\r\n",
      "\u001b[34mdata\u001b[m\u001b[m\r\n",
      "image_crawler.ipynb\r\n",
      "\u001b[31mkeras 튜토리얼 (국문).ipynb\u001b[m\u001b[m\r\n",
      "labels_test.csv\r\n",
      "labels_train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvEJNjInPyN7"
   },
   "source": [
    "# Preparation\n",
    "\n",
    "(아래 코드들 설명)\n",
    "1. `original_data.zip` 파일을 다운로드 한다. (카톡방 참고)\n",
    "2. 아래 코드를 실행시키고 `original_data.zip`을 업로드 한다.\n",
    "3. 압축을 푼다. (미견도사, 진돗개, 삽살개 각각 하나의 폴더가 존재함)\n",
    "4. `train_test_ratio` 를 정하고 `random.random()` 을 돌려 각 데이터를 `/train` 폴더나 `/test` 폴더에 복사한다\n",
    "5. 각 폴더(`train`/`test`)에 들어있는 데이터를 바탕으로 csv를 만든다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "geQq7NA4PepS",
    "outputId": "4ca0b631-e3e2-4c6d-d0ec-e3e655b73400"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0a01fbe9dbca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2. 아래 코드를 실행시키고 original_data.zip을 업로드 한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# original_data.zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# 2. 아래 코드를 실행시키고 original_data.zip을 업로드 한다.\n",
    "from google.colab import files\n",
    "files.upload()  # original_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5C9cuW4EPkim"
   },
   "outputs": [],
   "source": [
    "# 3. 압축을 푼다. (미견도사, 진돗개, 삽살개 각각 하나의 폴더가 존재함)\n",
    "!unzip original_copies.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uWkqrsYBR8P-",
    "outputId": "740364d4-e96f-4c3a-cf71-585291bce408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "/Users/yuyejin/Documents/동아리/Ybigta/프로젝트/data\n",
      "/Users/yuyejin/Documents/동아리/Ybigta/프로젝트\n"
     ]
    }
   ],
   "source": [
    "# If data/train and data/test folders exist already, skip this block.\n",
    "!mkdir data\n",
    "%cd data\n",
    "!mkdir train test\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# image rename\n",
    "classes = ['dosamastiff', 'jindotgae', 'sapsalgae']\n",
    "for c in classes:\n",
    "    dirpath = os.path.join('data', c) #data/c 로 경로 설정\n",
    "    files = os.listdir(dirpath)\n",
    "    i = 1\n",
    "    for f in files:\n",
    "        fpath = os.path.join(dirpath, f)\n",
    "        newpath = os.path.join('dataset', f'{c}_{i}.jpg')\n",
    "        os.rename(fpath, newpath)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PQZIlcaKQ9iI"
   },
   "outputs": [],
   "source": [
    "# 4. train_test_ratio 를 정하고 random.random() 을 돌려 각 데이터를 /train 폴더나 /test 폴더에 복사한다\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# For reproducibility\n",
    "# random.seed(42)\n",
    "\n",
    "classes = ['dosamastiff', 'jindotgae', 'sapsalgae']\n",
    "train_test_split = 0.2\n",
    "\n",
    "for c in classes:\n",
    "  dirpath = join('data', c) #data/c 로 경로 설정\n",
    "  files = os.listdir(dirpath)\n",
    "  for f in files:\n",
    "    fpath = join(dirpath, f)\n",
    "    folder = 'test' if random.random() < train_test_split else 'train'\n",
    "    new_dir = join('data', folder)\n",
    "    shutil.copy(fpath, new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_EZ3OhEWSizY"
   },
   "outputs": [],
   "source": [
    "# 5. 각 폴더(train/test)에 들어있는 데이터를 바탕으로 csv를 만든다.\n",
    "import pandas as pd\n",
    "\n",
    "for folder in ['train', 'test']:\n",
    "  fnames = os.listdir(join('data', folder))\n",
    "  ids = pd.Series(fnames)\n",
    "  labels = list(ids.map(lambda x: x.split('_')[0]))\n",
    "  df = pd.DataFrame({'id':ids, 'breed':labels})\n",
    "  df.to_csv(f'labels_{folder}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2yyoDhsWsgP"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NLugkTAeWuKd"
   },
   "outputs": [],
   "source": [
    "import keras as k\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications import xception\n",
    "\n",
    "NUM_CLS = 3\n",
    "SIZE = (299,299)\n",
    "\n",
    "def img_and_label(img_id, train_test, size):\n",
    "    cls = img_id.split('_')[0]\n",
    "    img = image.load_img(os.path.join('data', train_test, img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Rw2KNeg5W2fD"
   },
   "outputs": [],
   "source": [
    "labels_train = pd.read_csv('labels_train.csv')\n",
    "X_train = np.zeros((len(labels_train), *SIZE, 3))\n",
    "y_train = np.zeros((len(labels_train), NUM_CLS))\n",
    "\n",
    "labels_test = pd.read_csv('labels_test.csv')\n",
    "X_test = np.zeros((len(labels_test), *SIZE, 3))\n",
    "y_test = np.zeros(len(labels_test))\n",
    "\n",
    "y_template = {'dosamastiff':0, 'jindotgae':1, 'sapsalgae':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "dUOBKidbW77m",
    "outputId": "e2fdc6ee-1e19-4135-f548-0488914f6ae0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_101.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_103.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_104.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_106.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_107.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_108.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dosamastiff</td>\n",
       "      <td>dosamastiff_109.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         breed                   id\n",
       "0  dosamastiff    dosamastiff_1.jpg\n",
       "1  dosamastiff  dosamastiff_100.jpg\n",
       "2  dosamastiff  dosamastiff_101.jpg\n",
       "3  dosamastiff  dosamastiff_102.jpg\n",
       "4  dosamastiff  dosamastiff_103.jpg\n",
       "5  dosamastiff  dosamastiff_104.jpg\n",
       "6  dosamastiff  dosamastiff_106.jpg\n",
       "7  dosamastiff  dosamastiff_107.jpg\n",
       "8  dosamastiff  dosamastiff_108.jpg\n",
       "9  dosamastiff  dosamastiff_109.jpg"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('data/jindotgae')) + len(os.listdir('data/sapsalgae')) + len(os.listdir('data/dosamastiff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xKmuICnzW93u"
   },
   "outputs": [],
   "source": [
    "for i, fname in enumerate(labels_train['id']):\n",
    "    img, label = img_and_label(fname, 'train', SIZE)\n",
    "    x = xception.preprocess_input(img[np.newaxis,:,:,:])\n",
    "    X_train[i] = x\n",
    "    \n",
    "    # y_train needs to be one-hot\n",
    "    y_train[i, y_template[label]] = 1\n",
    "    \n",
    "for i, fname in enumerate(labels_test['id']):\n",
    "    img, label = img_and_label(fname, 'test', SIZE)\n",
    "    x = xception.preprocess_input(img[np.newaxis,:,:,:])\n",
    "    X_test[i] = x\n",
    "    \n",
    "    # y_test need not be one-hot\n",
    "    y_test[i] = y_template[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "kWWHV_Z-XuX-",
    "outputId": "0e064388-6d85-4018-8f25-222c644751fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 299, 299, 3)\n",
      "(389, 3)\n",
      "(104, 299, 299, 3)\n",
      "(104,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "5Rm0c9TwZjJE",
    "outputId": "1f4231b7-5d2e-4d0c-a2d4-c1e7da9dc3ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tl-En7I8ZoIV"
   },
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IQRcZ4TWZkv0"
   },
   "outputs": [],
   "source": [
    "# Data agmentation\n",
    "datagen = image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RBNzrLMEifq8"
   },
   "outputs": [],
   "source": [
    "POOLING = 'avg'\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "\n",
    "base_model = xception.Xception(include_top=False, weights='imagenet', input_shape=(299,299,3), pooling=POOLING)\n",
    "x = base_model.output\n",
    "pred = k.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = k.models.Model(inputs=base_model.input, outputs=pred)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "print('Model loaded and compiled. Now starting training...')\n",
    "\n",
    "model.fit_generator(\n",
    "    datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch= int(len(X_train) / BATCH_SIZE),\n",
    "    epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vG0yz2JPZs0l"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KsSv8bCMZwhC"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred_vec = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8NY_-ryNZ5gf"
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "np.mean(y_test == pred_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uGr33fviZ8pw"
   },
   "outputs": [],
   "source": [
    "# 작성중\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wrong_idx = (y_test != prev_vec)\n",
    "wrong_data = labels_test[wrong_idx]\n",
    "\n",
    "# Visualise 16 wrong images\n",
    "wrong_ids = wrong_data.head(16)['id']\n",
    "wrong_labels = wrong_data.head(16)['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         ...,\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n",
       "\n",
       "        [[ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         ...,\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n",
       "\n",
       "        [[ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         ...,\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         ...,\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n",
       "\n",
       "        [[ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         ...,\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ]],\n",
       "\n",
       "        [[ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         ...,\n",
       "         [ 0.9764706 ,  0.9764706 ,  0.9764706 ],\n",
       "         [ 0.9843137 ,  0.9843137 ,  0.9843137 ],\n",
       "         [ 0.8901961 ,  0.8901961 ,  0.8745098 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.04313731, -0.05882353, -0.20784312],\n",
       "         [ 0.06666672, -0.03529412, -0.18431371],\n",
       "         [ 0.09803927, -0.00392157, -0.15294117],\n",
       "         ...,\n",
       "         [ 0.5372549 ,  0.41960788,  0.254902  ],\n",
       "         [ 0.54509807,  0.427451  ,  0.24705887],\n",
       "         [ 0.5529412 ,  0.4431373 ,  0.23921573]],\n",
       "\n",
       "        [[ 0.06666672, -0.03529412, -0.18431371],\n",
       "         [ 0.09019613, -0.01176471, -0.1607843 ],\n",
       "         [ 0.10588241,  0.00392163, -0.14509803],\n",
       "         ...,\n",
       "         [ 0.54509807,  0.427451  ,  0.26274514],\n",
       "         [ 0.54509807,  0.427451  ,  0.24705887],\n",
       "         [ 0.56078434,  0.45098042,  0.24705887]],\n",
       "\n",
       "        [[ 0.13725495,  0.03529418, -0.11372548],\n",
       "         [ 0.16078436,  0.05882359, -0.09019607],\n",
       "         [ 0.16078436,  0.05882359, -0.09019607],\n",
       "         ...,\n",
       "         [ 0.5529412 ,  0.43529415,  0.27058828],\n",
       "         [ 0.56078434,  0.4431373 ,  0.26274514],\n",
       "         [ 0.5764706 ,  0.4666667 ,  0.26274514]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3960784 , -0.3490196 , -0.36470586],\n",
       "         [-0.38823527, -0.34117645, -0.35686272],\n",
       "         [-0.38039213, -0.3333333 , -0.3490196 ],\n",
       "         ...,\n",
       "         [-0.42745095, -0.38039213, -0.3960784 ],\n",
       "         [-0.42745095, -0.38039213, -0.3960784 ],\n",
       "         [-0.3960784 , -0.3490196 , -0.36470586]],\n",
       "\n",
       "        [[-0.38039213, -0.3333333 , -0.3490196 ],\n",
       "         [-0.372549  , -0.32549018, -0.34117645],\n",
       "         [-0.372549  , -0.32549018, -0.34117645],\n",
       "         ...,\n",
       "         [-0.41960782, -0.372549  , -0.38823527],\n",
       "         [-0.4352941 , -0.38823527, -0.40392154],\n",
       "         [-0.41960782, -0.372549  , -0.38823527]],\n",
       "\n",
       "        [[-0.372549  , -0.32549018, -0.34117645],\n",
       "         [-0.372549  , -0.32549018, -0.34117645],\n",
       "         [-0.372549  , -0.32549018, -0.34117645],\n",
       "         ...,\n",
       "         [-0.41176468, -0.36470586, -0.38039213],\n",
       "         [-0.42745095, -0.38039213, -0.3960784 ],\n",
       "         [-0.42745095, -0.38039213, -0.3960784 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.20784312,  0.0196079 , -0.01960784],\n",
       "         [-0.20784312,  0.0196079 , -0.01960784],\n",
       "         [-0.21568626,  0.01176476, -0.02745098],\n",
       "         ...,\n",
       "         [ 0.07450986,  0.16078436,  0.11372554],\n",
       "         [ 0.05098045,  0.12941182,  0.12156868],\n",
       "         [ 0.03529418,  0.11372554,  0.10588241]],\n",
       "\n",
       "        [[-0.31764704, -0.08235294, -0.09803921],\n",
       "         [-0.29411763, -0.06666666, -0.08235294],\n",
       "         [-0.2862745 , -0.05882353, -0.0745098 ],\n",
       "         ...,\n",
       "         [ 0.02745104,  0.11372554,  0.06666672],\n",
       "         [ 0.02745104,  0.10588241,  0.09803927],\n",
       "         [-0.00392157,  0.07450986,  0.06666672]],\n",
       "\n",
       "        [[-0.46666664, -0.24705881, -0.23921567],\n",
       "         [-0.47450978, -0.25490195, -0.24705881],\n",
       "         [-0.47450978, -0.24705881, -0.26274508],\n",
       "         ...,\n",
       "         [ 0.03529418,  0.12156868,  0.09019613],\n",
       "         [ 0.06666672,  0.14509809,  0.13725495],\n",
       "         [ 0.07450986,  0.15294123,  0.14509809]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.01960784, -0.26274508, -0.5058824 ],\n",
       "         [-0.01960784, -0.26274508, -0.5058824 ],\n",
       "         [-0.05882353, -0.2862745 , -0.5372549 ],\n",
       "         ...,\n",
       "         [ 0.39607847,  0.11372554, -0.16862744],\n",
       "         [ 0.36470592,  0.082353  , -0.19999999],\n",
       "         [ 0.47450984,  0.20784318, -0.08235294]],\n",
       "\n",
       "        [[ 0.00392163, -0.25490195, -0.5137255 ],\n",
       "         [-0.05098039, -0.2862745 , -0.5529412 ],\n",
       "         [-0.08235294, -0.32549018, -0.5686275 ],\n",
       "         ...,\n",
       "         [ 0.45098042,  0.18431377, -0.10588235],\n",
       "         [ 0.5137255 ,  0.24705887, -0.02745098],\n",
       "         [ 0.39607847,  0.12941182, -0.14509803]],\n",
       "\n",
       "        [[ 0.06666672, -0.19215685, -0.45098037],\n",
       "         [ 0.02745104, -0.20784312, -0.47450978],\n",
       "         [-0.09803921, -0.32549018, -0.5764706 ],\n",
       "         ...,\n",
       "         [ 0.4039216 ,  0.13725495, -0.1372549 ],\n",
       "         [ 0.4901961 ,  0.22352946, -0.05098039],\n",
       "         [ 0.45098042,  0.1686275 , -0.08235294]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 0.99215686,  0.99215686,  0.99215686],\n",
       "         ...,\n",
       "         [ 0.827451  ,  0.9137255 ,  0.8509804 ],\n",
       "         [ 0.92156863,  0.99215686,  0.96862745],\n",
       "         [ 0.92156863,  0.99215686,  0.9529412 ]],\n",
       "\n",
       "        [[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 0.6392157 ,  0.69411767,  0.6313726 ],\n",
       "         [ 0.84313726,  0.8980392 ,  0.84313726],\n",
       "         [ 0.8901961 ,  0.96862745,  0.90588236]],\n",
       "\n",
       "        [[ 0.99215686,  0.99215686,  0.99215686],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 0.49803925,  0.54509807,  0.4666667 ],\n",
       "         [ 0.45882356,  0.5058824 ,  0.39607847],\n",
       "         [ 0.60784316,  0.67058825,  0.58431375]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.85882354,  1.        ,  1.        ],\n",
       "         [ 0.7882353 ,  0.90588236,  0.94509804],\n",
       "         [ 0.73333335,  0.8117647 ,  0.88235295],\n",
       "         ...,\n",
       "         [ 0.77254903,  0.827451  ,  0.8745098 ],\n",
       "         [ 0.8509804 ,  0.9372549 ,  0.96862745],\n",
       "         [ 0.67058825,  0.7411765 ,  0.78039217]],\n",
       "\n",
       "        [[ 0.41176474,  0.5058824 ,  0.6156863 ],\n",
       "         [ 0.64705884,  0.7490196 ,  0.8117647 ],\n",
       "         [ 0.43529415,  0.5764706 ,  0.6862745 ],\n",
       "         ...,\n",
       "         [ 0.27058828,  0.34901965,  0.41960788],\n",
       "         [ 0.827451  ,  0.8980392 ,  0.96862745],\n",
       "         [ 0.70980394,  0.78039217,  0.8352941 ]],\n",
       "\n",
       "        [[ 0.5294118 ,  0.6313726 ,  0.75686276],\n",
       "         [ 0.07450986,  0.20784318,  0.36470592],\n",
       "         [ 0.4431373 ,  0.58431375,  0.6784314 ],\n",
       "         ...,\n",
       "         [ 0.79607844,  0.8666667 ,  0.92156863],\n",
       "         [ 0.64705884,  0.7176471 ,  0.77254903],\n",
       "         [ 0.88235295,  0.94509804,  0.96862745]]],\n",
       "\n",
       "\n",
       "       [[[ 0.48235297, -0.1607843 , -0.25490195],\n",
       "         [ 0.47450984, -0.16862744, -0.26274508],\n",
       "         [ 0.45882356, -0.1607843 , -0.26274508],\n",
       "         ...,\n",
       "         [ 0.01176476, -0.02745098, -0.0745098 ],\n",
       "         [ 0.0196079 , -0.01176471, -0.08235294],\n",
       "         [-0.02745098, -0.0745098 , -0.16862744]],\n",
       "\n",
       "        [[ 0.4666667 , -0.1607843 , -0.24705881],\n",
       "         [ 0.45882356, -0.16862744, -0.25490195],\n",
       "         [ 0.45882356, -0.15294117, -0.25490195],\n",
       "         ...,\n",
       "         [ 0.01176476, -0.01960784, -0.09019607],\n",
       "         [ 0.03529418,  0.00392163, -0.06666666],\n",
       "         [-0.04313725, -0.0745098 , -0.1607843 ]],\n",
       "\n",
       "        [[ 0.45882356, -0.16862744, -0.25490195],\n",
       "         [ 0.45882356, -0.16862744, -0.25490195],\n",
       "         [ 0.4666667 , -0.14509803, -0.23921567],\n",
       "         ...,\n",
       "         [ 0.01176476, -0.01960784, -0.09019607],\n",
       "         [ 0.04313731,  0.01176476, -0.05882353],\n",
       "         [-0.04313725, -0.06666666, -0.1372549 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9843137 ,  0.99215686,  0.9529412 ],\n",
       "         [ 0.9843137 ,  0.9764706 ,  0.94509804],\n",
       "         [ 0.9607843 ,  0.96862745,  0.90588236],\n",
       "         ...,\n",
       "         [ 0.70980394,  0.54509807,  0.30196083],\n",
       "         [ 0.6862745 ,  0.4901961 ,  0.254902  ],\n",
       "         [ 0.62352943,  0.43529415,  0.2313726 ]],\n",
       "\n",
       "        [[ 0.9843137 ,  0.99215686,  0.9529412 ],\n",
       "         [ 0.99215686,  0.99215686,  0.9764706 ],\n",
       "         [ 0.99215686,  0.99215686,  0.9764706 ],\n",
       "         ...,\n",
       "         [ 0.6784314 ,  0.4901961 ,  0.28627455],\n",
       "         [ 0.69411767,  0.5137255 ,  0.26274514],\n",
       "         [ 0.6627451 ,  0.5058824 ,  0.2941177 ]],\n",
       "\n",
       "        [[ 0.9843137 ,  0.99215686,  0.9529412 ],\n",
       "         [ 0.9843137 ,  0.9843137 ,  0.96862745],\n",
       "         [ 0.9843137 ,  0.9843137 ,  0.96862745],\n",
       "         ...,\n",
       "         [ 0.654902  ,  0.4666667 ,  0.27843142],\n",
       "         [ 0.67058825,  0.47450984,  0.23921573],\n",
       "         [ 0.67058825,  0.5058824 ,  0.2941177 ]]],\n",
       "\n",
       "\n",
       "       [[[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ]],\n",
       "\n",
       "        [[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ]],\n",
       "\n",
       "        [[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2941177 ,  0.13725495, -0.32549018],\n",
       "         [ 0.28627455,  0.09803927, -0.45098037],\n",
       "         [ 0.26274514,  0.0196079 , -0.62352943],\n",
       "         ...,\n",
       "         [ 0.00392163,  0.0196079 , -0.00392157],\n",
       "         [ 0.05098045,  0.02745104, -0.02745098],\n",
       "         [ 0.05882359,  0.05098045,  0.0196079 ]],\n",
       "\n",
       "        [[ 0.20000005,  0.00392163, -0.41960782],\n",
       "         [ 0.04313731, -0.29411763, -0.7254902 ],\n",
       "         [-0.02745098, -0.21568626, -0.6862745 ],\n",
       "         ...,\n",
       "         [ 0.0196079 ,  0.0196079 , -0.04313725],\n",
       "         [ 0.03529418,  0.01176476, -0.02745098],\n",
       "         [ 0.05882359,  0.06666672,  0.02745104]],\n",
       "\n",
       "        [[ 0.2941177 ,  0.19215691, -0.05882353],\n",
       "         [-0.04313725, -0.38823527, -0.75686276],\n",
       "         [-0.19215685, -0.4588235 , -0.8117647 ],\n",
       "         ...,\n",
       "         [ 0.00392163, -0.00392157, -0.04313725],\n",
       "         [ 0.0196079 ,  0.01176476, -0.00392157],\n",
       "         [ 0.02745104,  0.0196079 , -0.01176471]]]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "temp[0][0][0][0] = temp[0][0][0][0].astype('float32')\n",
    "print(type(temp[0][0][0][0]))\n",
    "print(type(temp[0][0][0][0].astype('float32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a in range(0, len(temp)):\n",
    "    for b in range(0, len(temp[a])):\n",
    "        for c in range(0, len(temp[a][b])):\n",
    "            for d in range(0, len(temp[a][b][c])):\n",
    "                temp[a][b][c][d] = temp[a][b][c][d].astype('float32')\n",
    "                print(type(temp[a][b][c][d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN 모델을 정의합니다. \n",
    "def cifar(x):\n",
    "    \n",
    "      \"\"\"CIFAR-10 이미지를 분류하기 위한 Convolutional Neural Networks 그래프를 생성합니다.\n",
    "      인자들(Args):\n",
    "        x: (N_examples, 32, 32, 3) 차원을 가진 input tensor, CIFAR-10 데이터는 32x32 크기의 컬러이미지이다.\n",
    "      리턴값들(Returns):\n",
    "        tuple (y, keep_prob). y는 (N_examples, 10)형태의 숫자(0-9) tensor이다. \n",
    "        keep_prob는 dropout을 위한 scalar placeholder이다.\n",
    "      \"\"\"\n",
    "\n",
    "      # 입력 이미지\n",
    "      x_image = x\n",
    "\n",
    "      # 첫번째 convolutional layer - 하나의 grayscale 이미지를 64개의 특징들(feature)으로 맵핑(maping)한다.\n",
    "      W_conv1 = tf.Variable(tf.truncated_normal(shape=[5, 5, 3, 64], stddev=5e-2))\n",
    "      b_conv1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "      h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1)\n",
    "\n",
    "      # 첫번째 Pooling layer\n",
    "      h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "      # 두번째 convolutional layer -- 32개의 특징들(feature)을 64개의 특징들(feature)로 맵핑(maping)한다.\n",
    "      W_conv2 = tf.Variable(tf.truncated_normal(shape=[5, 5, 64, 64], stddev=5e-2))\n",
    "      b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "      h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2)\n",
    "\n",
    "      # 두번째 pooling layer.\n",
    "      h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "      # 세번째 convolutional layer\n",
    "      W_conv3 = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], stddev=5e-2))\n",
    "      b_conv3 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "      h_conv3 = tf.nn.relu(tf.nn.conv2d(h_pool2, W_conv3, strides=[1, 1, 1, 1], padding='SAME') + b_conv3)\n",
    "\n",
    "      # 네번째 convolutional layer\n",
    "      W_conv4 = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=5e-2))\n",
    "      b_conv4 = tf.Variable(tf.constant(0.1, shape=[128])) \n",
    "      h_conv4 = tf.nn.relu(tf.nn.conv2d(h_conv3, W_conv4, strides=[1, 1, 1, 1], padding='SAME') + b_conv4)\n",
    "\n",
    "      # 다섯번째 convolutional layer\n",
    "      W_conv5 = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=5e-2))\n",
    "      b_conv5 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "      h_conv5 = tf.nn.relu(tf.nn.conv2d(h_conv4, W_conv5, strides=[1, 1, 1, 1], padding='SAME') + b_conv5)\n",
    "\n",
    "      # Fully Connected Layer 1 -- 2번의 downsampling 이후에, 우리의 32x32 이미지는 8x8x128 특징맵(feature map)이 된다.\n",
    "      # 이를 384개의 특징들로 맵핑(maping)한다.\n",
    "      W_fc1 = tf.Variable(tf.truncated_normal(shape=[8 * 8 * 128, 384], stddev=5e-2))\n",
    "      b_fc1 = tf.Variable(tf.constant(0.1, shape=[384]))\n",
    "\n",
    "      h_conv5_flat = tf.reshape(h_conv5, [-1, 8*8*128])\n",
    "      h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "      # Dropout - 모델의 복잡도를 컨트롤한다. 특징들의 co-adaptation을 방지한다.\n",
    "      h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) \n",
    "\n",
    "      # 384개의 특징들(feature)을 10개의 클래스-airplane, automobile, bird...-로 맵핑(maping)한다.\n",
    "      W_fc2 = tf.Variable(tf.truncated_normal(shape=[384, 10], stddev=5e-2))\n",
    "      b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "      logits = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
    "      y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "      return y_pred, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN 모델을 정의합니다. \n",
    "def build_CNN_classifier():\n",
    "    \n",
    "      # input\n",
    "      x_image = tf.placeholder(tf.float32, [None, 299, 299, 3])\n",
    "\n",
    "      # 첫번째 convolutional layer \n",
    "      W_conv1 = tf.Variable(tf.truncated_normal(shape=[5, 5, 3, 64], stddev=5e-2))\n",
    "      b_conv1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "        \n",
    "      h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1)\n",
    "\n",
    "      # 첫번째 Pooling layer\n",
    "      h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "      # 두번째 convolutional layer \n",
    "      W_conv2 = tf.Variable(tf.truncated_normal(shape=[5, 5, 64, 64], stddev=5e-2))\n",
    "      b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "      h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2)\n",
    "\n",
    "      # 두번째 pooling layer.\n",
    "      h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "      # 세번째 convolutional layer\n",
    "      W_conv3 = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], stddev=5e-2))\n",
    "      b_conv3 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "      h_conv3 = tf.nn.relu(tf.nn.conv2d(h_pool2, W_conv3, strides=[1, 1, 1, 1], padding='SAME') + b_conv3)\n",
    "\n",
    "      # 네번째 convolutional layer\n",
    "      W_conv4 = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=5e-2))\n",
    "      b_conv4 = tf.Variable(tf.constant(0.1, shape=[128])) \n",
    "      h_conv4 = tf.nn.relu(tf.nn.conv2d(h_conv3, W_conv4, strides=[1, 1, 1, 1], padding='SAME') + b_conv4)\n",
    "\n",
    "      # 다섯번째 convolutional layer\n",
    "      W_conv5 = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=5e-2))\n",
    "      b_conv5 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "      h_conv5 = tf.nn.relu(tf.nn.conv2d(h_conv4, W_conv5, strides=[1, 1, 1, 1], padding='SAME') + b_conv5)\n",
    "\n",
    "      # Fully Connected Layer 1\n",
    "      W_fc1 = tf.Variable(tf.truncated_normal(shape=[8 * 8 * 128, 384], stddev=5e-2))\n",
    "      b_fc1 = tf.Variable(tf.constant(0.1, shape=[384]))\n",
    "\n",
    "      h_conv5_flat = tf.reshape(h_conv5, [-1, 8*8*128])\n",
    "      h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "      # Dropout \n",
    "      h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) \n",
    "\n",
    "      W_fc2 = tf.Variable(tf.truncated_normal(shape=[384, 3], stddev=5e-2))\n",
    "      b_fc2 = tf.Variable(tf.constant(0.1, shape=[3]))\n",
    "      logits = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
    "      y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "      return x_image, y_pred, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-124-403fceac811e>:9: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scalar 형태의 레이블(0~9)을 One-hot Encoding 형태로 변환합니다.\n",
    "#y_train_one_hot = tf.squeeze(tf.one_hot(y_train, 10),axis=1)\n",
    "#y_test_one_hot = tf.squeeze(tf.one_hot(y_test, 10),axis=1)\n",
    "\n",
    "# Convolutional Neural Networks(CNN) 그래프를 생성합니다.\n",
    "x_images, y_pred, logits = build_CNN_classifier()\n",
    "\n",
    "# Cross Entropy를 비용함수(loss function)으로 정의하고, RMSPropOptimizer를 이용해서 비용 함수를 최소화합니다.\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "train_step = tf.train.RMSPropOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "# 정확도를 계산하는 연산을 추가합니다.\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 세션을 열어 실제 학습을 진행합니다.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(y_pred, feed_dict={x_image: X_train})\n",
    "  \n",
    "    # 10000 Step만큼 최적화를 수행합니다.\n",
    "    for i in range(10000):\n",
    "        batch = next_batch(128, X_train, y_train())\n",
    "\n",
    "    # 100 Step마다 training 데이터셋에 대한 정확도와 loss를 출력합니다.\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "        loss_print = loss.eval(feed_dict={X: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "\n",
    "        print(\"반복(Epoch): %d, 트레이닝 데이터 정확도: %f, 손실 함수(loss): %f\" % (i, train_accuracy, loss_print))\n",
    "        print(\"Current time is : \", datetime.datetime.now())\n",
    "    # 20% 확률의 Dropout을 이용해서 학습을 진행한다.\n",
    "    sess.run(train_step, feed_dict={X: batch[0], y: batch[1], keep_prob: 0.8})\n",
    "\n",
    "    # 학습이 끝나면 테스트 데이터에 대한 정확도를 출력합니다.  \n",
    "    test_batch = next_batch(10000, X_test, y_test)\n",
    "    print(\"테스트 데이터 정확도: %f\" % accuracy.eval(feed_dict={X: test_batch[0], y: test_batch[1], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YBIGTA Transfer Learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
